---
title: NTUML - Deep Learning - When Gradient Is Small Local Minimum and Saddle Point
---

<!-- more -->

<iframe src="https://www.youtube.com/embed/QW6uINn7uGk" allowfullscreen></iframe>



![image-20210422161242303](https://lllthhhh-aliyun-oss.oss-cn-beijing.aliyuncs.com/img/20210422161242.png)

不能说卡在了local minima , 要考虑 saddle point 的情况 **critical point**

![image-20210422161525106](https://lllthhhh-aliyun-oss.oss-cn-beijing.aliyuncs.com/img/20210422161525.png)

![image-20210422161551445](https://lllthhhh-aliyun-oss.oss-cn-beijing.aliyuncs.com/img/20210422161551.png)

![image-20210422161709384](https://lllthhhh-aliyun-oss.oss-cn-beijing.aliyuncs.com/img/20210422161709.png)

![image-20210422162003644](https://lllthhhh-aliyun-oss.oss-cn-beijing.aliyuncs.com/img/20210422162003.png)

![image-20210422162120253](https://lllthhhh-aliyun-oss.oss-cn-beijing.aliyuncs.com/img/20210422162120.png)

![image-20210422162553331](https://lllthhhh-aliyun-oss.oss-cn-beijing.aliyuncs.com/img/20210422162553.png)

求出$H$的特征值特征向量, 就可以得到下一步的方向

![image-20210422162702913](https://lllthhhh-aliyun-oss.oss-cn-beijing.aliyuncs.com/img/20210422162703.png)

但是实践上, 计算 **Hessian** 复杂度比较高, 一般不使用

提出了低维度的local minima可能在高维中是saddle point

实际中, 参数很多, local minima的情况非常少发生, 往往卡在saddle point

![image-20210422163346205](https://lllthhhh-aliyun-oss.oss-cn-beijing.aliyuncs.com/img/20210422163346.png)

---

